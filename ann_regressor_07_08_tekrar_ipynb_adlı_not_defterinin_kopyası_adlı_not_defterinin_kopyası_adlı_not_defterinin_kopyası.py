# -*- coding: utf-8 -*-
"""ANN_Regressor_07_08_tekrar.ipynb adlı not defterinin kopyası adlı not defterinin kopyası adlı not defterinin kopyası

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s8XCvHBlglYjG-zG0VX150-Hnzce9o9o

# ANN (Artificial Neural Network)
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Import Necessary Libraries"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math
from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV
from sklearn.preprocessing import LabelEncoder, RobustScaler, MinMaxScaler, StandardScaler
from sklearn import model_selection
from sklearn.neural_network import MLPRegressor
import pickle
import joblib

# Settings
pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", None)
pd.set_option("display.width", 500)

import warnings
warnings.filterwarnings("ignore")

"""# Import Dataset"""

adv = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/datasets/Hitters[1].csv")
df = adv.copy()
df.head()

"""# General Information About to Dataset"""

def check_df(dataframe, head=5):
    print(20*"#", "HEAD", 20*"#")
    print(dataframe.head(head))
    print(20*"#", "TAIL", 20*"#")
    print(dataframe.tail(head))
    print(20*"#", "SHAPE", 20*"#")
    print(dataframe.shape)
    print(20*"#", "TYPES", 20*"#")
    print(dataframe.dtypes)
    print(20*"#", "NA", 20*"#")
    print(dataframe.isnull().sum())
    print(20*"#", "QUARTILES", 20*"#")
    print(dataframe.describe([0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]).T)

check_df(df)

"""# Analysis of Catgeorical and Numerical Variables"""

def grab_col_names(dataframe, cat_th=10, car_th=20, report=False):
    # category
    cat_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in  ["category", "object", "bool"]]
    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes in ["uint8", "int64", "float64"]]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and str(dataframe[col].dtypes) in ["category", "object"]]
    cat_cols = cat_cols + num_but_cat
    # numerical
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes in ["uint8", "int64", "float64"]]
    num_cols = [col for col in num_cols if col not in cat_cols]
    # report
    if report:
        print(f"Observation: {dataframe.shape[0]}")
        print(f"Variables: {dataframe.shape[1]}")
        print(f"Categrical Columns: {len(cat_cols)}")
        print(f"Numerical Columns: {len(num_cols)}")
        print(f"Categorical But Cardinality: {len(cat_but_car)}")
        print(f"Numerical But Categorical: {len(num_but_cat)}")
    return cat_cols, num_but_cat, cat_but_car, num_cols

cat_cols, num_but_cat, cat_but_car, num_cols = grab_col_names(df, report=True)

def num_summary(dataframe, col_name, plot=False):
    print(20*"#", col_name, 20*"#")
    quantiles = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]
    print(dataframe[col_name].describe(quantiles).T)
    if plot:
        dataframe[col_name].hist(bins=20)
        plt.xlabel(col_name)
        plt.ylabel(col_name)
        plt.show()

def num_summary_df(dataframe):
    cat_cols, num_but_cat, cat_but_car, num_cols = grab_col_names(dataframe)
    for col in num_cols:
        num_summary(dataframe, col, plot=True)

num_summary_df(df)

def plot_num_summary(dataframe):
    cat_cols, num_but_cat, cat_but_car, num_cols = grab_col_names(dataframe)
    num_plots = len(num_cols)
    rows = math.ceil(num_plots/2)
    cols = 2 if num_plots > 1 else 1
    plt.figure(figsize=(10*cols, 4*rows))
    for index, col in enumerate(num_cols):
        plt.subplot(rows, cols, index+1)
        plt.tight_layout()
        dataframe[col].hist(bins=20)
        plt.title(col)

plot_num_summary(df)

"""# Correlation Analysis"""

def high_correlated_cols(dataframe, corr_th=0.9, remove=False, plot=False):
    num_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in ["uint8", "int64", "float64"]]
    corr = dataframe[num_cols].corr()
    corr_matrix = corr.abs()
    upper_triangle_matrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]
    if drop_list == []:
        print(20*"#", "After correlation analaysis, you do not need to remove variables", 20*"#")
    if remove:
        dataframe = dataframe.drop(drop_list, axis=1)
    if plot:
        num_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in ["uint8", "int64", "float64"]]
        sns.set(rc={'figure.figsize': (18, 13)})
        sns.heatmap(dataframe[num_cols].corr(), cmap="RdBu", annot=True, fmt=".2f")
        plt.show()
    return drop_list

drop_list = high_correlated_cols(df, remove=False, plot=True)

drop_list

"""# Missing Value Analysis"""

df.isnull().sum()

def missing_value_table(dataframe):
  na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]
  n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)
  ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)
  missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=["n_miss", "ratio"])
  print(missing_df)

missing_value_table(df)

def fill_na_with_median(dataframe):
  dataframe = dataframe.apply(lambda x: x.fillna(x.median()) if x.dtype not in ["category", "object", "bool"] else x, axis=0)
  return dataframe

df = fill_na_with_median(df)

df.isnull().sum().sum()

"""# Encoding"""

def label_encoder(dataframe, binary_col):
  labelencoder = LabelEncoder()
  dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])
  return dataframe

def label_encoder_df(dataframe):
  binary_cols = [col for col in dataframe.columns if dataframe[col].dtype not in ["int", "float"] and dataframe[col].nunique() == 2]
  for col in binary_cols:
    label_encoder(dataframe, col)
  return dataframe

def one_hot_encoding(dataframe):
  cat_cols = [col for col in dataframe.columns if  10 >= dataframe[col].nunique() > 2]
  dataframe = pd.get_dummies(dataframe, columns=cat_cols, drop_first=True)
  label_encoder_df(dataframe)
  return dataframe

df = one_hot_encoding(df)

df.head()

"""# ANN (Artificial Nerual Network)"""

def ANN_Regressor(dataframe, target,  test_size=0.20, results=False,save_model=False):
  X = dataframe.drop(target, axis=1)
  y = dataframe[target]
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)
  #scaler = StandardScaler()
  #X_train = scaler.fit_transform(X_train)
  #X_test = scaler.fit_transform(X_test)
  ann_model = MLPRegressor().fit(X_train, y_train)


  if results:
    mse_train = mean_squared_error(y_train, ann_model.predict(X_train))
    mse_test = mean_squared_error(y_test, ann_model.predict(X_test))
    rmse_train = root_mean_squared_error(y_train, ann_model.predict(X_train))
    rmse_test = root_mean_squared_error(y_test, ann_model.predict(X_test))
    mae_train = mean_absolute_error(y_train, ann_model.predict(X_train))
    mae_test = mean_absolute_error(y_test, ann_model.predict(X_test))
    r2_train = r2_score(y_train, ann_model.predict(X_train))
    r2_test = r2_score(y_test, ann_model.predict(X_test))
    print("MSE Train: ", "%.3f" % mse_train)
    print("MSE Test: ", "%.3f" % mse_test)
    print("RMSE Train: ", "%.3f" % rmse_train)
    print("RMSE Test: ", "%.3f" % rmse_test)
    print("MAE Train: ", "%.3f" % mae_train)
    print("MAE Test: ", "%.3f" % mae_test)
    print("R2 Train: ", "%.3f" % r2_train)
    print("R2 Test: ", "%.3f" % r2_test)

  if save_model:
    joblib.dump(ann_model, "ann_model.pkl")

  return ann_model

ann_model = ANN_Regressor(df, "Salary",  test_size=0.20, results=True,save_model=True)

new_player = df.sample()

new_player

new_player_without_target = new_player.drop("Salary", axis=1)

def new_data_predict2(new_data, model_path):
  model_disc = joblib.load(model_path)
  print(f"Prediction: {model_disc.predict(new_data)[0]}")

new_data_predict2(new_player_without_target, "ann_model.pkl")

"""# ANN Model Tuning"""

def ANN_Regressor_Tuning(dataframe, target, test_size=0.20, cv=10, results=False, save_model=False):
  X = dataframe.drop(target, axis=1)
  y = dataframe[target]
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)
  #scaler = StandardScaler()
  #X_train = scaler.fit_transform(X_train)
  #X_test = scaler.fit_transform(X_test)
  ann_model = MLPRegressor()
  ann_params = {"alpha" : [0.1, 0.2, 0.02, 0.3, 0.03, 0.4],
                "hidden_layer_sizes" : [(100,50), (100,100,50), (200,100,50), (300, 200, 100, 50)]}
  ann_cv_model = GridSearchCV(ann_model, ann_params, cv=cv, verbose=1, n_jobs=-1).fit(X_train,y_train)
  ann_model_tuned = MLPRegressor(alpha=ann_cv_model.best_params_["alpha"],
                                 hidden_layer_sizes=ann_cv_model.best_params_["hidden_layer_sizes"]).fit(X_train, y_train)

  if results:
    mse_train = mean_squared_error(y_train, ann_model_tuned.predict(X_train))
    mse_test = mean_squared_error(y_test, ann_model_tuned.predict(X_test))
    rmse_train = root_mean_squared_error(y_train, ann_model_tuned.predict(X_train))
    rmse_test = root_mean_squared_error(y_test, ann_model_tuned.predict(X_test))
    mae_train = mean_absolute_error(y_train, ann_model_tuned.predict(X_train))
    mae_test = mean_absolute_error(y_test, ann_model_tuned.predict(X_test))
    r2_train = r2_score(y_train, ann_model_tuned.predict(X_train))
    r2_test = r2_score(y_test, ann_model_tuned.predict(X_test))
    print(f"K Best Parmas: {ann_cv_model.best_params_}")
    print("MSE Train: ", "%.3f" % mse_train)
    print("MSE Test: ", "%.3f" % mse_test)
    print("RMSE Train: ", "%.3f" % rmse_train)
    print("RMSE Test: ", "%.3f" % rmse_test)
    print("MAE Train: ", "%.3f" % mae_train)
    print("MAE Test: ", "%.3f" % mae_test)
    print("R2 Train: ", "%.3f" % r2_train)
    print("R2 Test: ", "%.3f" % r2_test)

  if save_model:
    joblib.dump(ann_model_tuned, "ann_model_tuned.pkl")
    print("Model Tuned Saved...")

  return ann_model_tuned

ann_model_tuned = ANN_Regressor_Tuning(df, "Salary", test_size=0.20, cv=10, results=True, save_model=True)

new_data_predict2(new_player_without_target, "ann_model_tuned.pkl")

